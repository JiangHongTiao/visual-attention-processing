#summary Modelling Primate Visual Attention.

= Overview =
<wiki:toc depth='1'/>

= Details =

== Introduction ==
The primate attentions are hypothesized to be based on both bottom-up (image-based) and top-down (task dependent) cues. 
Attention does not only serves to select a location of interest but also enhance the cortical representation of that location. 
Vision relies on interactions between coarse, massively parallel, full-field pre-attentive analysis systems and the more detailed, circumscribed and sequential attentional system.
Critical aspects of selective visual attention:
 # What are brain areas involved in its control and deployment ?
 # What are mechanisms by which attention is attracted in a bottom-up or image-based manner towards conspicuous or salient locations in our visual environment ?
 # What are mechanisms by which attention modulates the early sensory representation of attended stimuli ?
 # What are mechanisms for top-down or voluntary deployment of attention ?
 # What is the interaction between attention, object recognition and scene undertaking ?
== Brain areas ==

 A cooperation between "two visual systems":
 * Selecting where to attend next is controlled by the dorsal visual processing stream ( "where/how" stream) which comprises cortical areas in posterior parietal cortex.
 * Localizing object recognition is controlled by the cortical areas in inferotemporal cortex ( "what" stream) which concerns with localized object recognition.

== Bottom-up control ==

 An operation mode of attention so called bottom-up control is unconscious and driven by the specific attributes of the stimuli.

=== Visual search and pop-out ===

 The pop-out searches suggest the target can be effortlessly found by relying on the pre-attentive visual processing over the entire visual scene.
 The conjunctive searches suggest that attending to the target is a necessary precondition to identify it as being the unique target; therefore it requires that the search array be scanned until the target is chosen.
 
=== Computational Models and the saliency map ===

Only fairly simple visual features are computed in a massively parallel manner over the entire incoming visual scene.

Three main steps of bottom-up architectures

 * Early stages of visual processing decompose the incoming visual input image into feature maps. After that feature maps are integrated together to give saliency maps.
 * Winner-take-all neural networks are used to get the most attended point.
 * Inhibition-of-return mechanism prevents attention from permanently focusing onto the most active location.

 Wolfe hypothesized that the selection of relevant features for a given search task could be performed top-down, through spatially-defined and feature-dependent weightting of the various feature maps.
 
 Tsotsos implemented attentional seelction using a combination of feedforward bottom-up feature extraction hierarchy and feedback selective tuning of these feature extraction mechanisms.

 Itti proposed a purely bottom-up model, in which spatial competition for saliency is directly modelled after non-classical surround modulation effects. 

== Top-down modulation of early vision ==

 Feedback from higher centers to early processing stages 

=== Are we blind outside of the focus of attention ===

 Unless we attend to an object, we are unlikely to perceive any details or detect any changes.

=== Attentional modulation of early vision ===

 Dual-task psycho-physical experiments
 Attention does not implement a feed-forward, bottom-up information processing bottleneck. Rather attention enhances, through feedback, early visual processing for both the location and visual features being attended to.

== Top-down deployment of attention ===

Two questions:

How may attention be deployed on a purely voluntary bsis onto one of several identical stimuli ?

How do eye movements dramatically influenced by the question being answered ?

=== Attentional facilitation and cuing ===

The voluntarily shifting attention towards a stimulus improves the perception of that stimulus.

We appear to voluntarily select not only where to attend to, but also the specific features of a stimulus to be attended.

=== Influence of task ===

The task demands play a critical role in determining where attention is to be focused next.

Stark and colleagues have proposed the scanpath theory of attention, according to which eye movements are generated almost exclusively under top-down control.

The theory proposes that what we see is only remotely related to the patterns of activation of our retina.

== Attention scene and understanding ==

How  from a very brief presentation of a scene we are able to extract its gist, basic layout, and a number of other characteristics.

How several computer vision models have used a collaboration between the where and what subsystems to yield sophisticated scene recognition algorithms.

=== Is scene understanding purely attentional? ===

A very fast visual subsystem which operates in parallel with attention allows us to rapidly derive the gist and coarse layout of a novel visual scene. This rapid subsystem is one of the key components by which attention may be guided top-down towards specific visual locations.

=== Cooperation between where and what ===

Interesting examples of cooperation between a fast attentional cueing system and a slower localized feature analysis system

Teasing apart the brain mechanisms by which attention, localized recognition, and rapid computation of scene gist and layout collaborate in normal vision remains one of the most exciting challenges for modern visual neuroscience.

=== Attention as a component of vision ===

Issues: 
 * Internal representation of scenes and objects
 * The level of detail with which scenes are stored in memory for later recall and comparison

 Think of attention within the broader framework of vision and scene understanding

== Discussion ==

 Thought tremedous progress has been made over the past century of the scientific study of attention, many of key components of this complex interacting system remain poorly understood and elusive, thus posing ever renewed challenges for future neuroscience research.